{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f995e896",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('sample_data/100QA.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1016d43",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"?\", \"\")\n",
    "    text = text.replace(\"'\", \"\")\n",
    "    return text.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99bfad6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "vocab = {\"<UNK>\": 0}\n",
    "def build_vocab(row):\n",
    "    q = tokenize(row.question)\n",
    "    a = tokenize(row.answer)\n",
    "    for word in q + a:\n",
    "        if word not in vocab:\n",
    "            vocab[word] = len(vocab)\n",
    "\n",
    "df.apply(build_vocab, axis='columns')\n",
    "# axis = 1 is also ok\n",
    "\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48a8716",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def text_to_indices(text, vocab):\n",
    "    indices = []\n",
    "    for word in tokenize(text):\n",
    "        if word in vocab:\n",
    "            indices.append(vocab[word])\n",
    "        else:\n",
    "            indices.append(vocab[\"<UNK>\"])\n",
    "    return indices\n",
    "\n",
    "text_to_indices(df.question[1], vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f503d2d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, df, vocab):\n",
    "        self.df = df\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        q = text_to_indices(row.question, self.vocab)\n",
    "        a = text_to_indices(row.answer, self.vocab)\n",
    "        return torch.tensor(q), torch.tensor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa426e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset = QADataset(df, vocab)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "for q, a in dataloader:\n",
    "    print(q, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83d0096",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# class SimpleRNN(nn.Module):\n",
    "#     def __init__(self, vocab_size):\n",
    "#         super().__init__()\n",
    "#         self.embedding = nn.Embedding(vocab_size, 50)\n",
    "#         self.RNN = nn.RNN(50, 64)\n",
    "#         self.fc = nn.Linear(64, vocab_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         pass\n",
    "\n",
    "# x = nn.Embedding(324, 50)\n",
    "# # dataset[0][0], x(dataset[0][0]).shape\n",
    "# a = x(dataset[0][0])\n",
    "# y = nn.RNN(50, 64)\n",
    "# # y(a)[0].shape, y(a)[1].shape, y(a)[0], y(a)[1]\n",
    "# # pehle vale ne 6 vectors diye (O(1), O(2), ... O(6)) aur dusre ne 1 diya (O(6))\n",
    "# b = y(a)[1]\n",
    "# z = nn.Linear(64, 324)\n",
    "# # z(b).shape, z(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8aa5d2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, 50)\n",
    "        self.rnn = nn.RNN(50, 64, batch_first=True)\n",
    "        self.fc = nn.Linear(64, vocab_size) # fc = fully connected layer\n",
    "        # yahan pe nn.Sequential (jo sirf ek hi output ko pass on karna allow karta hai) use nhi\n",
    "        # kar sakte kyuki hame 2 outputs mil rhe hain jo ki dono ham next layer me bhej rhe hain\n",
    "\n",
    "    def forward(self, question):\n",
    "        hidden, final = self.rnn(self.embedding(question))\n",
    "        return self.fc(final.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987ddfd8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 50\n",
    "\n",
    "model = SimpleRNN(len(vocab))\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1736be8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "x = nn.Embedding(324, 50)\n",
    "y = nn.RNN(50, 64, batch_first=True)\n",
    "z = nn.Linear(64, 324)\n",
    "a = dataset[0][0].reshape(1, 6)\n",
    "b = x(a)\n",
    "c, d = y(b)\n",
    "e = z(d.squeeze(0))\n",
    "a.shape, b.shape, c.shape, d.shape, e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c21d2c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for q, a in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(model(q), a[0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {total_loss/len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcb0e2f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, question, threshold=0.5):\n",
    "    question_tensor = torch.tensor(text_to_indices(question, vocab)).unsqueeze(0)\n",
    "    output = model(question_tensor)\n",
    "    probs = nn.functional.softmax(output, dim=1)\n",
    "    value, index = torch.max(probs, dim=1)\n",
    "    if value < threshold:\n",
    "        print(\"I don't know\", value)\n",
    "    else:\n",
    "        print(list(vocab.keys())[index], value)\n",
    "\n",
    "predict(model, \"what is the largest planet in our solar system\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
